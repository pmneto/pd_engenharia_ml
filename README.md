
# Projeto: Preditor de Arremessos do Kobe Bryant ğŸ€

Este projeto foi desenvolvido como parte da disciplina de Engenharia de Machine Learning, seguindo o framework **TDSP (Team Data Science Process)**, e cumpre integralmente as rubricas exigidas na avaliaÃ§Ã£o, integrando ferramentas como **Kedro**, **MLflow**, **PyCaret**, **Streamlit** e **Docker**.

---

## ğŸ“¦ Estrutura do Projeto

```
engenharia_ml_kobe/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Dados brutos de desenvolvimento e produÃ§Ã£o
â”‚   â”œâ”€â”€ processed/            # Dados pÃ³s-processamento (filtrados)
â”‚   â””â”€â”€ model_output/         # MÃ©tricas, grÃ¡ficos e inferÃªncias
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda_kobe.ipynb        # AnÃ¡lise exploratÃ³ria dos dados
â”œâ”€â”€ conf/base/                # CatÃ¡logo Kedro + parÃ¢metros de configuraÃ§Ã£o
â”œâ”€â”€ src/
â”‚   â””â”€â”€ engenharia_ml_kobe/   # Pipelines, nodes e pipelines de aplicaÃ§Ã£o
â”œâ”€â”€ README.md
â””â”€â”€ docker-compose.yml
```

---

## âœ… Etapas realizadas e justificativas

### 1. Coleta e categorizaÃ§Ã£o dos dados via API pÃºblica

- Os dados foram baixados de URLs pÃºblicas usando `requests`.
- Foram salvos em `/data/raw/` como `dataset_kobe_dev.parquet` e `dataset_kobe_prod.parquet`.

### 2. PrÃ©-processamento dos dados

- Criado o pipeline `PreparacaoDados`, que:
  - Renomeia colunas para `snake_case`
  - Remove duplicatas e valores nulos
  - Substitui `lon` por `lng` para padronizaÃ§Ã£o
  - Seleciona colunas especÃ­ficas:
    `['lat', 'lng', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']`
- Dados filtrados salvos em `/data/processed/data_filtered.parquet`

### 3. Treinamento de modelos

- Utilizado `PyCaret` para experimentar mÃºltiplos modelos de classificaÃ§Ã£o:
  - **RegressÃ£o LogÃ­stica** (como baseline obrigatÃ³rio)
  - **Ãrvore de DecisÃ£o** e **AdaBoostClassifier**
- Os modelos foram logados no **MLflow** com mÃ©tricas:
  - Log Loss, F1 Score, AcurÃ¡cia, AUC, Recall e PrecisÃ£o.

### 4. AplicaÃ§Ã£o em produÃ§Ã£o

- Pipeline aplica o modelo treinado na base de produÃ§Ã£o (`dataset_kobe_prod.parquet`).
- Verifica aderÃªncia do modelo Ã  nova base.
- Resultados salvos em `model_output/predicoes_prod.parquet`.

### 5. Monitoramento e Retreinamento

- Criado dashboard com **Streamlit** para:
  - Visualizar mÃ©tricas e inferÃªncias
  - Simular cenÃ¡rio com/sem variÃ¡vel alvo
- EstratÃ©gias propostas:
  - **Reativa**: Reprocessar a cada x perÃ­odos se o desempenho cair
  - **Preditiva**: DetecÃ§Ã£o de drift e agendamento automÃ¡tico

---

## ğŸ³ Executando com Docker

1. Compile a imagem e suba os containers:
```bash
docker-compose up --build
```

2. Os serviÃ§os estarÃ£o disponÃ­veis em:
- MLflow: http://localhost:5000
- Streamlit: http://localhost:8501
- API (se configurada): http://localhost:8000

---

## ğŸ“‘ Rodando a pipeline Kedro

No terminal dentro do container, execute:
```bash
kedro run
```

Para executar uma etapa especÃ­fica:
```bash
kedro run --from-nodes "PreparacaoDados"
```

---

## ğŸ“Š AnÃ¡lise exploratÃ³ria

Notebook disponÃ­vel em:
ğŸ‘‰ `notebooks/eda_kobe.ipynb`

Inclui visualizaÃ§Ã£o de:
- DistribuiÃ§Ã£o da variÃ¡vel alvo
- DispersÃ£o de `lat` vs `lng`
- CorrelaÃ§Ã£o entre variÃ¡veis

---

## ğŸ“‚ Artefatos gerados

Algumas imagens, grÃ¡ficos e arquivos de apoio foram salvos em:

- `data/processed/` â†’ Dados prontos para modelagem
- `data/model_output/` â†’ InferÃªncias da base de produÃ§Ã£o
- `mlruns/` â†’ Logs e modelos versionados

---

## ğŸ”— ConclusÃ£o

Projeto entregue conforme solicitado, com atenÃ§Ã£o especial aos critÃ©rios avaliativos da disciplina. Caso deseje revisar ou complementar qualquer parte, sinta-se Ã  vontade para sugerir ajustes!

