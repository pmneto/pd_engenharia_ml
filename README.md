
# Projeto: Preditor de Arremessos do Kobe Bryant ğŸ€

Este projeto foi desenvolvido como parte da disciplina de Engenharia de Machine Learning, seguindo o framework **TDSP (Team Data Science Process)**, e segue integralmente as rubricas exigidas na avaliaÃ§Ã£o, integrando ferramentas como **Kedro**, **MLflow**, **PyCaret**, **Streamlit** e **Docker**.

---

## ğŸ“¦ Estrutura do Projeto

```
â”œâ”€â”€ dashboard_streamlit.py
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ 01_raw
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_kobe_dev.parquet
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_kobe_prod.parquet
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ .gitkeep
â”‚Â Â  â”‚Â Â  â””â”€â”€ nba_court.png
â”‚Â Â  â”œâ”€â”€ 02_intermediate
â”‚Â Â  â”‚Â Â  â””â”€â”€ .gitkeep
â”‚Â Â  â”œâ”€â”€ 03_primary
â”‚Â Â  â”‚Â Â  â””â”€â”€ .gitkeep
â”‚Â Â  â”œâ”€â”€ 04_feature
â”‚Â Â  â”‚Â Â  â””â”€â”€ .gitkeep
â”‚Â Â  â”œâ”€â”€ 05_model_input
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_kobe_prod.parquet
â”‚Â Â  â”‚Â Â  â””â”€â”€ .gitkeep
â”‚Â Â  â”œâ”€â”€ 06_models
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ best_classifier.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ .gitkeep
â”‚Â Â  â”‚Â Â  â””â”€â”€ logistic_model.pkl
â”‚Â Â  â”œâ”€â”€ 07_model_output
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ .gitkeep
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ metricas_modelo_escolhido.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ metricas_modelo_escolhido_reg_log.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ metricas_producao.csv
â”‚Â Â  â”‚Â Â  â””â”€â”€ predictions_prod.parquet
â”‚Â Â  â”œâ”€â”€ 08_reporting
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ confusion_matrix.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ confusion_matrix_reg_log.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ .gitkeep
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ prediction_map.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ prediction_map_prod.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ prediction_map_raw_data.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ prediction_map_reg_log.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ roc_curve.png
â”‚Â Â  â”‚Â Â  â””â”€â”€ roc_curve_reg_log.png
â”‚Â Â  â”œâ”€â”€ processed
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data_filtered.parquet
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data_filtered_prod.parquet
â”‚Â Â  â”‚Â Â  â””â”€â”€ .gitkeep
â”‚Â Â  â””â”€â”€ raw
â”‚Â Â      â”œâ”€â”€ dataset_kobe_dev.parquet
â”‚Â Â      â””â”€â”€ dataset_kobe_prod.parquet
â”œâ”€â”€ docs
â”‚Â Â  â””â”€â”€ source
â”‚Â Â      â”œâ”€â”€ conf.py
â”‚Â Â      â”œâ”€â”€ engenhariaml_kobe.jpg
â”‚Â Â      â””â”€â”€ index.rst
â”œâ”€â”€ .gitignore
â”œâ”€â”€ info.log
â”œâ”€â”€ logs.log
â”œâ”€â”€ lynx_help_main.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.in
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ serve_model_streamlit.py
â””â”€â”€ src
    â””â”€â”€ engenharia_ml_kobe
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ __main__.py
        â”œâ”€â”€ pipeline_registry.py
        â”œâ”€â”€ pipelines
        â”‚Â Â  â”œâ”€â”€ application
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ nodes.py
        â”‚Â Â  â”‚Â Â  â””â”€â”€ pipeline.py
        â”‚Â Â  â”œâ”€â”€ data_engineering
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ nodes.py
        â”‚Â Â  â”‚Â Â  â””â”€â”€ pipeline.py
        â”‚Â Â  â”œâ”€â”€ data_science
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ nodes.py
        â”‚Â Â  â”‚Â Â  â””â”€â”€ pipeline.py
        â”‚Â Â  â””â”€â”€ __init__.py
        â””â”€â”€ settings.py

```

---

## âœ… Etapas realizadas e justificativas

### 1. Coleta e categorizaÃ§Ã£o dos dados via API pÃºblica

- Os dados foram baixados de URLs pÃºblicas usando `requests`.
- Foram salvos em `/data/01_raw/` como `dataset_kobe_dev.parquet` e `dataset_kobe_prod.parquet`.

### 2. PrÃ©-processamento dos dados

- Criado o pipeline `PreparacaoDados`, que:
  - Renomeia colunas para `snake_case`
  - Remove duplicatas e valores nulos
  - Substitui `lon` por `lng` para padronizaÃ§Ã£o
  - Seleciona colunas especÃ­ficas:
    `['lat', 'lng', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']`
- Dados filtrados salvos em `/data/processed/data_filtered.parquet` 

**Obs.: o diretÃ³rio data/processed foi levado em conta estritamente por estar escrito e solicitado desta maneira no enunciado.**

### 3. Treinamento de modelos

- Utilizado `PyCaret` para experimentar mÃºltiplos modelos de classificaÃ§Ã£o:
  - **RegressÃ£o LogÃ­stica** (como baseline obrigatÃ³rio)
  - **Ãrvore de DecisÃ£o** e **AdaBoostClassifier**
- Os modelos foram logados no **MLflow** com mÃ©tricas:
  - Log Loss, F1 Score, AcurÃ¡cia, AUC, Recall e PrecisÃ£o.

### 4. AplicaÃ§Ã£o em produÃ§Ã£o

- Pipeline aplica o modelo treinado na base de produÃ§Ã£o (`dataset_kobe_prod.parquet`).
- Verifica aderÃªncia do modelo Ã  nova base.
- Resultados salvos em `model_output/predicoes_prod.parquet`.

### 5. Monitoramento e Retreinamento

- Criado dashboard com **Streamlit** para:
  - Visualizar mÃ©tricas e inferÃªncias
  - Simular cenÃ¡rio com/sem variÃ¡vel alvo
- EstratÃ©gias propostas:
  - **Reativa**: Reprocessar a cada x perÃ­odos se o desempenho cair
  - **Preditiva**: DetecÃ§Ã£o de drift e agendamento automÃ¡tico

---

## ğŸ³ Executando com Docker

1. Compile a imagem e suba os containers:
```bash
docker-compose up --build
```

2. Os serviÃ§os estarÃ£o disponÃ­veis em:
- MLflow: http://localhost:5000
- Streamlit (dashboard): http://localhost:8501
- Streamlit (Serve Model UI): http://localhost:8502
- MLflow (API para servir o Modelo): http://localhost:5000/<RUN_ID>/model
---

## ğŸ“‘ Rodando a pipeline Kedro

No terminal dentro do container, execute:
```bash
kedro run
```

Para executar uma etapa especÃ­fica:
```bash
kedro run --from-nodes "PreparacaoDados"
```

---

## ğŸ“Š AnÃ¡lise exploratÃ³ria

Notebook disponÃ­vel em:
ğŸ‘‰ `notebooks/eda_kobe.ipynb`

Inclui visualizaÃ§Ã£o de:
- DistribuiÃ§Ã£o da variÃ¡vel alvo
- DispersÃ£o de `lat` vs `lng`
- CorrelaÃ§Ã£o entre variÃ¡veis

---

## ğŸ“‚ Artefatos gerados

Algumas imagens, grÃ¡ficos e arquivos de apoio foram salvos em:

- `data/processed/` â†’ Dados prontos para modelagem
- `data/model_output/` â†’ InferÃªncias da base de produÃ§Ã£o
- `mlruns/` â†’ Logs e modelos versionados

---

## ğŸ”— ConclusÃ£o

Projeto entregue conforme solicitado, com atenÃ§Ã£o especial aos critÃ©rios avaliativos da disciplina. 



---

## ğŸ”InstruÃ§Ãµes e Justificativas Complementares

### ğŸ”— RepositÃ³rio do Docker

Este projeto tambÃ©m conta com um repositÃ³rio dedicado Ã  infraestrutura Docker, onde estÃ£o definidos os serviÃ§os para o MLFlow, API de prediÃ§Ã£o e o Streamlit Dashboard:

â¡ï¸ **https://github.com/pmneto/engenhariaml-docker**

Nele estÃ£o os arquivos `Dockerfile`, `docker-compose.yml` e scripts de inicializaÃ§Ã£o da infraestrutura.

Esta solicitaÃ§Ã£o foi feita em aula pelo tutor onde por uma quantidade bastante grande de diferenÃ§as de ambientes e dificuldades em importaÃ§Ã£o de dependencias, foi sugerido/solicitado que fosse disponibilizado em docker o projeto.
---

### ğŸš€ Como executar os componentes do projeto

#### ğŸ“Š MLflow UI

Para visualizar o MLflow, basta rodar o seguinte comando dentro do ambiente Docker ou na mÃ¡quina local:

```bash
mlflow ui --port 5000
```

OU 

```bash
mlflow ui
```

A interface estarÃ¡ acessÃ­vel via:

```
http://localhost:5000
```

#### ğŸ¤– Servir modelo via MLflow

Para servir o modelo com base no Run ID registrado no MLflow, use:

```bash
mlflow models serve -m "runs:/<RUN_ID>/model" --port 1234
```

Substitua `<RUN_ID>` pelo ID da execuÃ§Ã£o de treinamento do modelo final.

#### ğŸ“ˆ Executar dashboard com Streamlit

Para visualizar o dashboard de monitoramento da operaÃ§Ã£o, rode:

```bash
streamlit run dashboard_streamlit.py
```
Para visualizar uma interface de usuÃ¡rio para o projeto:

```bash
streamlit run serve_model_streamlit.py
```
---

## âœ… Justificativas das EstratÃ©gias de Retreinamento (Rubrica 4.4)

Embora este projeto tenha sido desenvolvido como um trabalho final de disciplina, e portanto nÃ£o implemente efetivamente um ciclo de retreinamento em produÃ§Ã£o, Ã© importante refletir sobre como esse processo deveria acontecer em um ambiente real de MLOps.


ğŸ“Œ EstratÃ©gia Reativa
Uma abordagem reativa seria baseada no monitoramento contÃ­nuo de mÃ©tricas de desempenho do modelo, como o F1-score e o Log Loss, aplicadas diretamente sobre a base de produÃ§Ã£o. Esse monitoramento pode ser feito atravÃ©s do prÃ³prio MLflow UI, que registra as execuÃ§Ãµes de inferÃªncia e permite comparar resultados de versÃµes anteriores com a atual.

Por exemplo, se o modelo que estÃ¡ em operaÃ§Ã£o comeÃ§ar a apresentar uma degradaÃ§Ã£o nas mÃ©tricas (ex: F1-score caindo mais de 15% em relaÃ§Ã£o ao que foi observado na base de teste), isso pode servir como gatilho para retreinar o modelo com dados mais recentes.

ğŸ“Œ EstratÃ©gia Preditiva
JÃ¡ a abordagem preditiva seria implementada atravÃ©s de anÃ¡lises estatÃ­sticas das distribuiÃ§Ãµes dos dados de entrada, comparando os dados de produÃ§Ã£o com os dados originais usados para treinar o modelo. TÃ©cnicas como KS-Test ou DivergÃªncia de Jensen-Shannon podem ajudar a detectar quando as variÃ¡veis (ex: shot_distance, minutes_remaining, etc.) saem do padrÃ£o esperado, indicando um possÃ­vel "drift" nos dados.

Neste caso, mesmo que o desempenho ainda nÃ£o tenha caÃ­do significativamente, o sistema jÃ¡ seria capaz de prever que o modelo pode vir a se degradar, permitindo um retreinamento proativo.

---
